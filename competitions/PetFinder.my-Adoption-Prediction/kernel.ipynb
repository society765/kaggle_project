{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.6.7 (default, Dec  5 2018, 15:02:05) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n",
      "pandas version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy as sp \n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import zipfile, json\n",
    "import datetime as dt \n",
    "\n",
    "import sys, glob, os \n",
    "print('python version:', sys.version)\n",
    "print('pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read basic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:16:40.340796 start reading data\n",
      "kernel running environment: local\n",
      "data path: ../../../data/PetFinder.my-Adoption-Prediction/\n",
      "train data shape: (14993, 24)\n",
      "test data shape: (3948, 23)\n",
      "full data shape: (18941, 24)\n",
      "2019-03-12 04:16:40.561293 finish reading data\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start reading data')\n",
    "\n",
    "if os.path.isdir('../input') and not os.path.isfile('../input/test.zip'): \n",
    "    envx = 'remote' \n",
    "    dirc = '../input/'\n",
    "else: \n",
    "    envx = 'local'\n",
    "    dirc = '../../../data/PetFinder.my-Adoption-Prediction/'\n",
    "print('kernel running environment:', envx) \n",
    "print('data path:', dirc) \n",
    "\n",
    "train = pd.read_csv(dirc+'train/train.csv')\n",
    "test = pd.read_csv(dirc+'test/test.csv')\n",
    "sample_sub = pd.read_csv(dirc+'test/sample_submission.csv')\n",
    "\n",
    "print('train data shape:', train.shape)\n",
    "print('test data shape:', test.shape)\n",
    "\n",
    "data = pd.concat([train, test], sort=False)\n",
    "print('full data shape:', data.shape)\n",
    "\n",
    "breed_labels = pd.read_csv(dirc+'breed_labels.csv')\n",
    "color_labels = pd.read_csv(dirc+'color_labels.csv')\n",
    "state_labels = pd.read_csv(dirc+'state_labels.csv')\n",
    "\n",
    "print(dt.datetime.now(), 'finish reading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
      "0     2       Nibble    3     299       0       1       1       7       0   \n",
      "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
      "2     1       Brisco    1     307       0       1       2       7       0   \n",
      "3     1         Miko    4     307       0       2       1       2       0   \n",
      "4     1       Hunter    1     307       0       1       1       0       0   \n",
      "\n",
      "   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n",
      "0             1          1           2         2           2       1   \n",
      "1             2          2           3         3           3       1   \n",
      "2             2          2           1         1           2       1   \n",
      "3             2          1           1         1           2       1   \n",
      "4             2          1           2         2           2       1   \n",
      "\n",
      "   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n",
      "0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n",
      "1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
      "2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
      "3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n",
      "4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n",
      "\n",
      "                                         Description      PetID  PhotoAmt  \\\n",
      "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n",
      "1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n",
      "2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n",
      "3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n",
      "4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n",
      "\n",
      "   AdoptionSpeed  \n",
      "0              2  \n",
      "1              0  \n",
      "2              3  \n",
      "3              2  \n",
      "4              2  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 200):\n",
    "    print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start parsing data from sentiment and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmean(ary, key): \n",
    "    ''' \n",
    "    get mean value associated with 'key' from a iterable 'ary'\n",
    "    '''\n",
    "    return np.array([x.get(key, np.nan) for x in ary]).mean()\n",
    "\n",
    "def getsum(ary, key): \n",
    "    ''' \n",
    "    get sum value associated with 'key' from a iterable 'ary'\n",
    "    '''\n",
    "    return np.array([x.get(key, np.nan) for x in ary]).sum() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:16:40.721473 start getting sentiment\n",
      "train sentiment shape: (14442, 5)\n",
      "test sentiment shape (3815, 5)\n",
      "full sentiment shape (18257, 5)\n",
      "2019-03-12 04:16:45.418610 finish getting sentiment\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start getting sentiment')\n",
    "\n",
    "def get_sentiment(s): \n",
    "    '''\n",
    "    parse sentiment from a sentiment json file 's' \n",
    "    '''\n",
    "    docSentiMag = s['documentSentiment']['magnitude'] \n",
    "    docSentiScore = s['documentSentiment']['score']\n",
    "\n",
    "    mag_sco = [x['sentiment'] for x in s['sentences']]\n",
    "    \n",
    "    fullMag = getsum(mag_sco, 'magnitude')\n",
    "    fullScore = getsum(mag_sco, 'score')\n",
    "    \n",
    "    return [docSentiMag, docSentiScore, fullMag, fullScore]\n",
    "\n",
    "def get_sentiment_f(myfile): \n",
    "    '''\n",
    "    forward a file name string to get_sentiment \n",
    "    '''\n",
    "    s = json.load(open(myfile))       \n",
    "    return [myfile[myfile.rfind('/')+1:-5], *get_sentiment(s)]\n",
    "\n",
    "def get_sentiment_zip(zipfilename):\n",
    "    sentiment_proc = np.asarray([\n",
    "        get_sentiment_f(myfile) for myfile in glob.glob(zipfilename)\n",
    "    ])\n",
    "    df_senti = pd.DataFrame(sentiment_proc, \n",
    "             columns=['PetID', 'docSentiMag', 'docSentiScore', 'fullMag', 'fullScore'])  \n",
    "    df_senti['docSentiMag'] = df_senti['docSentiMag'].astype('float')\n",
    "    df_senti['docSentiScore'] = df_senti['docSentiScore'].astype('float')\n",
    "    df_senti['fullMag'] = df_senti['fullMag'].astype('float')\n",
    "    df_senti['fullScore'] = df_senti['fullScore'].astype('float')\n",
    "    return df_senti\n",
    "\n",
    " \n",
    "train_senti = get_sentiment_zip(dirc+'train_sentiment/*.json')\n",
    "test_senti = get_sentiment_zip(dirc+'test_sentiment/*.json')   \n",
    "data_senti = pd.concat([train_senti, test_senti], sort=False)\n",
    "\n",
    "print('train sentiment shape:', train_senti.shape)\n",
    "print('test sentiment shape', test_senti.shape)\n",
    "print('full sentiment shape', data_senti.shape)\n",
    "\n",
    "\n",
    "print(dt.datetime.now(), 'finish getting sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetID            0\n",
       "docSentiMag      0\n",
       "docSentiScore    0\n",
       "fullMag          0\n",
       "fullScore        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_senti.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18257 entries, 0 to 3814\n",
      "Data columns (total 5 columns):\n",
      "PetID            18257 non-null object\n",
      "docSentiMag      18257 non-null float64\n",
      "docSentiScore    18257 non-null float64\n",
      "fullMag          18257 non-null float64\n",
      "fullScore        18257 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 855.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_senti.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>docSentiMag</th>\n",
       "      <th>docSentiScore</th>\n",
       "      <th>fullMag</th>\n",
       "      <th>fullScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e6ff63097</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14831f659</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>065906a54</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03aae5768</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4dd90768</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  docSentiMag  docSentiScore  fullMag  fullScore\n",
       "0  e6ff63097          1.2            0.3      1.0        1.0\n",
       "1  14831f659          0.4           -0.4      0.4       -0.4\n",
       "2  065906a54          1.7            0.2      1.5        1.5\n",
       "3  03aae5768          1.1            0.5      1.0        1.0\n",
       "4  e4dd90768          2.9            0.5      2.7        2.7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_senti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:16:45.659661 start getting metadata\n",
      "train metadata shape: (58311, 7)\n",
      "test metadata shape (15040, 7)\n",
      "full metadata shape (73351, 7)\n",
      "2019-03-12 04:17:11.567676 finish getting metadata\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start getting metadata')\n",
    "\n",
    "def parse_metadata(s): \n",
    "    '''\n",
    "    parse metadata from a metadata json file 's' \n",
    "    '''\n",
    "    if 'labelAnnotations' in s: \n",
    "        s_label_Anno = s['labelAnnotations']\n",
    "        labelAnnoScore = getmean(s_label_Anno, 'score')\n",
    "        labelAnnoDesc = s_label_Anno[0]['description']\n",
    "    else: \n",
    "        labelAnnoScore = np.nan \n",
    "        labelAnnoDesc = np.nan\n",
    "\n",
    "    if 'imagePropertiesAnnotation' in s:\n",
    "        s_ipa_dom_colors = s['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        imagePropAnnoScore = getmean(s_ipa_dom_colors, 'score')\n",
    "        imagePropAnnoPixelFrac = getmean(s_ipa_dom_colors, 'pixelFraction')\n",
    "    else: \n",
    "        imagePropAnnoScore = np.nan \n",
    "        imagePropAnnoPixelFrac = np.nan\n",
    "\n",
    "    if 'cropHintsAnnotation' in s:\n",
    "        s_cHA = s['cropHintsAnnotation']['cropHints']\n",
    "        cropHintsAnnoConf = getmean(s_cHA, 'confidence')\n",
    "        cropHintAnnoImport = getmean(s_cHA, 'importanceFraction')\n",
    "    else: \n",
    "        cropHintsAnnoConf = np.nan \n",
    "        cropHintAnnoImport = np.nan\n",
    "\n",
    "    return [labelAnnoScore, labelAnnoDesc, \n",
    "              imagePropAnnoScore, imagePropAnnoPixelFrac, \n",
    "              cropHintsAnnoConf, cropHintAnnoImport]\n",
    "\n",
    "def parse_metadata_f(myfile): \n",
    "    s = json.load(open(myfile))\n",
    "    return [myfile[myfile.rfind('/')+1:myfile.rfind('-')], *parse_metadata(s)]\n",
    "\n",
    "def parse_metadata_zip(zipfilename): \n",
    "    metadata_proc = np.asarray([\n",
    "        parse_metadata_f(myfile) for myfile in glob.glob(zipfilename)\n",
    "    ])\n",
    "    df_metadata = pd.DataFrame(metadata_proc,\n",
    "                columns = ['PetID', \n",
    "                            'labelAnnoScore', 'labelAnnoDesc', \n",
    "                            'imagePropAnnoScore', 'imagePropAnnoPixelFrac', \n",
    "                            'cropHintsAnnoConf', 'cropHintAnnoImport'])\n",
    "    df_metadata['labelAnnoScore'] = df_metadata['labelAnnoScore'].astype('float')\n",
    "    df_metadata['imagePropAnnoScore'] = df_metadata['imagePropAnnoScore'].astype('float')\n",
    "    df_metadata['imagePropAnnoPixelFrac'] = df_metadata['imagePropAnnoPixelFrac'].astype('float')\n",
    "    df_metadata['cropHintsAnnoConf'] = df_metadata['cropHintsAnnoConf'].astype('float')\n",
    "    df_metadata['cropHintAnnoImport'] = df_metadata['cropHintAnnoImport'].astype('float')\n",
    "    return df_metadata\n",
    "\n",
    "train_metad = parse_metadata_zip(dirc+'train_metadata/*.json')\n",
    "test_metad = parse_metadata_zip(dirc+'test_metadata/*.json')\n",
    "data_metad = pd.concat([train_metad, test_metad], sort=False)\n",
    "\n",
    "print('train metadata shape:', train_metad.shape)\n",
    "print('test metadata shape', test_metad.shape)\n",
    "print('full metadata shape', data_metad.shape)  \n",
    "\n",
    "print(dt.datetime.now(), 'finish getting metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetID                      object\n",
       "labelAnnoScore            float64\n",
       "labelAnnoDesc              object\n",
       "imagePropAnnoScore        float64\n",
       "imagePropAnnoPixelFrac    float64\n",
       "cropHintsAnnoConf         float64\n",
       "cropHintAnnoImport        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metad.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>labelAnnoScore</th>\n",
       "      <th>labelAnnoDesc</th>\n",
       "      <th>imagePropAnnoScore</th>\n",
       "      <th>imagePropAnnoPixelFrac</th>\n",
       "      <th>cropHintsAnnoConf</th>\n",
       "      <th>cropHintAnnoImport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e736f4022</td>\n",
       "      <td>0.744926</td>\n",
       "      <td>floor</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f861fe441</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>dog breed</td>\n",
       "      <td>0.082835</td>\n",
       "      <td>0.074638</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6da1ee245</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.090962</td>\n",
       "      <td>0.048281</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8f32c880e</td>\n",
       "      <td>0.801786</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.079665</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ca31b395</td>\n",
       "      <td>0.793212</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.097187</td>\n",
       "      <td>0.091496</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  labelAnnoScore labelAnnoDesc  imagePropAnnoScore  \\\n",
       "0  e736f4022        0.744926         floor            0.097666   \n",
       "1  f861fe441        0.743300     dog breed            0.082835   \n",
       "2  6da1ee245        0.707046           cat            0.090962   \n",
       "3  8f32c880e        0.801786           dog            0.079665   \n",
       "4  9ca31b395        0.793212           cat            0.097187   \n",
       "\n",
       "   imagePropAnnoPixelFrac  cropHintsAnnoConf  cropHintAnnoImport  \n",
       "0                0.065789                0.8                 1.0  \n",
       "1                0.074638                0.8                 1.0  \n",
       "2                0.048281                0.8                 1.0  \n",
       "3                0.052886                0.8                 1.0  \n",
       "4                0.091496                0.8                 1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing data in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetID                      0\n",
       "labelAnnoScore            15\n",
       "labelAnnoDesc              0\n",
       "imagePropAnnoScore         0\n",
       "imagePropAnnoPixelFrac     0\n",
       "cropHintsAnnoConf          0\n",
       "cropHintAnnoImport        24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metad.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metad_missing_cols = ['labelAnnoScore', 'cropHintAnnoImport']\n",
    "\n",
    "myimputer = SimpleImputer() \n",
    "data_metad[data_metad_missing_cols] = myimputer.fit_transform(data_metad[data_metad_missing_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetID                     0\n",
       "labelAnnoScore            0\n",
       "labelAnnoDesc             0\n",
       "imagePropAnnoScore        0\n",
       "imagePropAnnoPixelFrac    0\n",
       "cropHintsAnnoConf         0\n",
       "cropHintAnnoImport        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metad.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group PetID from image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18473, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>labelAnnoScore</th>\n",
       "      <th>imagePropAnnoScore</th>\n",
       "      <th>imagePropAnnoPixelFrac</th>\n",
       "      <th>cropHintsAnnoConf</th>\n",
       "      <th>cropHintAnnoImport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.777046</td>\n",
       "      <td>0.071256</td>\n",
       "      <td>0.050027</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a290e4</td>\n",
       "      <td>0.752176</td>\n",
       "      <td>0.080857</td>\n",
       "      <td>0.057316</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000c21f80</td>\n",
       "      <td>0.776582</td>\n",
       "      <td>0.070803</td>\n",
       "      <td>0.054727</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000fb9572</td>\n",
       "      <td>0.765480</td>\n",
       "      <td>0.089756</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0011d7c25</td>\n",
       "      <td>0.784120</td>\n",
       "      <td>0.083866</td>\n",
       "      <td>0.075841</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  labelAnnoScore  imagePropAnnoScore  imagePropAnnoPixelFrac  \\\n",
       "0  0008c5398        0.777046            0.071256                0.050027   \n",
       "1  000a290e4        0.752176            0.080857                0.057316   \n",
       "2  000c21f80        0.776582            0.070803                0.054727   \n",
       "3  000fb9572        0.765480            0.089756                0.064844   \n",
       "4  0011d7c25        0.784120            0.083866                0.075841   \n",
       "\n",
       "   cropHintsAnnoConf  cropHintAnnoImport  \n",
       "0                0.8                 1.0  \n",
       "1                0.8                 1.0  \n",
       "2                0.8                 1.0  \n",
       "3                0.8                 1.0  \n",
       "4                0.8                 1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not data_metad.PetID.is_unique:\n",
    "    data_metad = data_metad.groupby('PetID').mean().reset_index()\n",
    "print(data_metad.shape)\n",
    "data_metad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join and Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:17:11.849846 start merging data\n",
      "impute columns with nan: ['docSentiMag', 'docSentiScore', 'fullMag', 'fullScore', 'labelAnnoScore', 'imagePropAnnoScore', 'imagePropAnnoPixelFrac', 'cropHintsAnnoConf', 'cropHintAnnoImport']\n",
      "2019-03-12 04:17:11.948629 finish merging data\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start merging data')\n",
    "\n",
    "data1 = data.copy()\n",
    "\n",
    "data1 = pd.merge(data1, data_senti, on='PetID', how='left')\n",
    "data1 = pd.merge(data1, data_metad, on='PetID', how='left')\n",
    "\n",
    "# Impute missing values, because Metadata or Sentiment is not complete \n",
    "data1_na_columns = list(data1.columns[\\\n",
    "                            (data1.isna().sum() != 0) & (data1.dtypes != 'object') \\\n",
    "                            ].drop('AdoptionSpeed'))\n",
    "print('impute columns with nan:', data1_na_columns)\n",
    "for col in data1_na_columns: \n",
    "    myimputer1 = SimpleImputer() \n",
    "    data1[col] = myimputer1.fit_transform(data1[col].values.reshape(-1, 1))\n",
    "\n",
    "# Irrelevant columns \n",
    "data1.drop(['Description', 'Name', 'RescuerID', 'PetID'], axis=1, inplace=True)\n",
    "\n",
    "# astype to int \n",
    "data1['PhotoAmt'] = data1.PhotoAmt.astype('int')\n",
    "\n",
    "print(dt.datetime.now(), 'finish merging data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummies for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:17:12.005762 start processing data\n",
      "(18941, 396)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18941 entries, 0 to 18940\n",
      "Columns: 396 entries, Type to State_41415\n",
      "dtypes: float64(10), int64(12), uint8(374)\n",
      "memory usage: 10.1 MB\n",
      "None\n",
      "2019-03-12 04:17:12.198654 finish processing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>...</th>\n",
       "      <th>State_41330</th>\n",
       "      <th>State_41332</th>\n",
       "      <th>State_41335</th>\n",
       "      <th>State_41336</th>\n",
       "      <th>State_41342</th>\n",
       "      <th>State_41345</th>\n",
       "      <th>State_41361</th>\n",
       "      <th>State_41367</th>\n",
       "      <th>State_41401</th>\n",
       "      <th>State_41415</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  \\\n",
       "0     2    3             1          1           2         2           2   \n",
       "1     2    1             2          2           2         2           2   \n",
       "2     1    1             2          2           1         1           2   \n",
       "3     1    4             2          1           1         1           2   \n",
       "4     1    1             2          1           2         2           2   \n",
       "\n",
       "   Health  Quantity  Fee  ...  State_41330  State_41332  State_41335  \\\n",
       "0       1         1  100  ...            0            0            0   \n",
       "1       1         1    0  ...            0            0            0   \n",
       "2       1         1    0  ...            0            0            0   \n",
       "3       1         1  150  ...            0            0            0   \n",
       "4       1         1    0  ...            0            0            0   \n",
       "\n",
       "   State_41336  State_41342  State_41345  State_41361  State_41367  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   State_41401  State_41415  \n",
       "0            0            0  \n",
       "1            1            0  \n",
       "2            0            0  \n",
       "3            1            0  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start processing data')\n",
    "\n",
    "# get_dummies \n",
    "col_dummied = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'State']\n",
    "data1_dummies = pd.get_dummies(data1[col_dummied].astype('object'))\n",
    "data1 = pd.concat([data1, data1_dummies], axis=1)\n",
    "data1.drop(col_dummied, axis=1, inplace=True)\n",
    "\n",
    "# 'Not Sure' in Vaccinated, Sterilized, or Dewormed -> 'No' \n",
    "col_not_sure = ['Vaccinated', 'Sterilized', 'Dewormed']\n",
    "for col in col_not_sure: \n",
    "    data1[col] = data1[col].map(lambda x: 2 if x == 3 else x)\n",
    "\n",
    "train1 = data1[data1.AdoptionSpeed.notna()]\n",
    "test1 = data1[data1.AdoptionSpeed.isna()].drop('AdoptionSpeed', axis=1)\n",
    "\n",
    "x = train1.drop('AdoptionSpeed', axis=1)\n",
    "y = train1['AdoptionSpeed'].astype('int')\n",
    "    \n",
    "print(data1.shape)\n",
    "print(data1.info(memory_usage='deep'))\n",
    "\n",
    "print(dt.datetime.now(), 'finish processing data')\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 04:17:12.301511 start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2.29762\n",
      "Will train until validation_0-rmse hasn't improved in 2000 rounds.\n",
      "[200]\tvalidation_0-rmse:1.11184\n",
      "[400]\tvalidation_0-rmse:1.06878\n",
      "[600]\tvalidation_0-rmse:1.06508\n",
      "[800]\tvalidation_0-rmse:1.06398\n",
      "[1000]\tvalidation_0-rmse:1.06292\n",
      "[1200]\tvalidation_0-rmse:1.0625\n",
      "[1400]\tvalidation_0-rmse:1.06283\n",
      "[1600]\tvalidation_0-rmse:1.06247\n",
      "[1800]\tvalidation_0-rmse:1.06269\n",
      "[2000]\tvalidation_0-rmse:1.06284\n",
      "[2200]\tvalidation_0-rmse:1.06316\n",
      "[2400]\tvalidation_0-rmse:1.06387\n",
      "[2600]\tvalidation_0-rmse:1.06471\n",
      "[2800]\tvalidation_0-rmse:1.06567\n",
      "[3000]\tvalidation_0-rmse:1.06631\n",
      "[3200]\tvalidation_0-rmse:1.06724\n",
      "[3400]\tvalidation_0-rmse:1.06766\n",
      "[3600]\tvalidation_0-rmse:1.06862\n",
      "Stopping. Best iteration:\n",
      "[1618]\tvalidation_0-rmse:1.06238\n",
      "\n",
      "2019-03-12 04:18:25.391911 finish training\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size = 0.10)\n",
    "\n",
    "def neg_quad_weighted_kappa(y_pred, dy_true): \n",
    "    return 'quadratic_weighted_kappa', -cohen_kappa_score(\n",
    "        dy_true.get_label(), np.argmax(y_pred, axis=1), weights='quadratic'\n",
    "    ) \n",
    "\n",
    "print(dt.datetime.now(), 'start training...')\n",
    "\n",
    "'''\n",
    "model_params = {'n_jobs': -1, 'tree_method': 'gpu_hist', 'learning_rate': 0.01, \n",
    "                'max_delta_step': 2, 'colsample_bylevel': 0.6, 'colsample_bytree': 0.1, \n",
    "                'gamma': 0.004, 'max_bin': 256, 'max_depth': 8, 'max_leaves': 27, \n",
    "                'min_child_weight': 96, \n",
    "                'reg_alpha': 0.003, 'reg_lambda': 0.060, 'subsample': 0.4}\n",
    "'''\n",
    "model_params = {'n_jobs': -1, 'tree_method': 'gpu_hist',\n",
    "                'boosting': 'gbdt', 'metric': 'rmse', 'num_leaves': 70, 'max_depth': 9,\n",
    "                'learning_rate': 0.01, 'bagging_fraction': 0.85, 'feature_fraction': 0.8,\n",
    "                'min_split_gain': 0.02, 'min_child_samples': 150, 'min_child_weight': 0.02,\n",
    "                'lambda_l2': 0.0475,  'verbosity': 200}\n",
    "#model = XGBClassifier(n_estimators=20000, **model_params) \n",
    "#model.fit(train_x, train_y, eval_set=[(val_x, val_y)], \n",
    "#          verbose=200, eval_metric=neg_quad_weighted_kappa, early_stopping_rounds=2000)\n",
    "#pred = model.predict(val_x) \n",
    "#print('cohen quadratic weighted kappa score:', cohen_kappa_score(val_y, pred, weights='quadratic'))\n",
    "\n",
    "model = XGBRegressor(n_estimators=20000, **model_params) \n",
    "model.fit(train_x, train_y, eval_set=[(val_x, val_y)], \n",
    "          verbose=200, eval_metric='rmse', early_stopping_rounds=2000)\n",
    "pred = model.predict(train_x) \n",
    "\n",
    "print(dt.datetime.now(), 'finish training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizer  \n",
    "Ref: https://www.kaggle.com/wrosinski/baselinemodeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Counts =  Counter({2: 425, 4: 403, 3: 330, 1: 296, 0: 46})\n",
      "Predicted Counts =  Counter({2.0: 536, 3.0: 450, 4.0: 263, 1.0: 251})\n",
      "Coefficients =  [ 0.54172229  2.00069959  2.46851556  2.98165246]\n",
      "QWK =  0.3872998706039128\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "\n",
    "\n",
    "# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "def rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# Compute QWK based on OOF train predictions:\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(\n",
    "    model.predict(train_x), train_y.values\n",
    ")\n",
    "coefficients = optR.coefficients()\n",
    "pred_test_y_k = optR.predict(\n",
    "    model.predict(val_x), coefficients\n",
    ")\n",
    "print(\"\\nValid Counts = \", Counter(val_y.values))\n",
    "print(\"Predicted Counts = \", Counter(pred_test_y_k))\n",
    "print(\"Coefficients = \", coefficients)\n",
    "\n",
    "qwk = quadratic_weighted_kappa(val_y, pred_test_y_k)\n",
    "print(\"QWK = \", qwk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              2\n",
       "1  73c10e136              3\n",
       "2  72000c4c5              4\n",
       "3  e147a4b9f              3\n",
       "4  43fbba852              3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_params = {'n_jobs': -1, 'tree_method': 'gpu_hist', 'learning_rate': 0.05}\n",
    "#model1 = XGBClassifier(n_estimators=model.best_iteration, **model_params) \n",
    "#model1.fit(x, y)\n",
    "\n",
    "sample_sub['AdoptionSpeed'] = optR.predict(\n",
    "                                model.predict(test1), coefficients \n",
    "                                )\n",
    "sample_sub['AdoptionSpeed'] = sample_sub['AdoptionSpeed'].astype('int')\n",
    "\n",
    "sample_sub.to_csv('submission.csv', index=False)\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
