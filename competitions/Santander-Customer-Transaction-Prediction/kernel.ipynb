{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-08 23:03:29.901141 python version:\n",
      "3.7.1 (default, Dec 14 2018, 19:28:38) \n",
      "[GCC 7.3.0]\n",
      "2019-03-08 23:03:29.901451 pandas version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import datetime as dt \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from xgboost import cv\n",
    "\n",
    "import sys \n",
    "\n",
    "print(dt.datetime.now(), 'python version:')\n",
    "print(sys.version)\n",
    "print(dt.datetime.now(), 'pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-08 23:03:31.501649 start reading data...\n",
      "2019-03-08 23:03:53.496686 finish reading data\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now(), 'start reading data...')\n",
    "\n",
    "dirc = '../input/'\n",
    "\n",
    "train = pd.read_csv(dirc + 'train.csv.zip', compression='zip')\n",
    "test = pd.read_csv(dirc + 'test.csv.zip', compression='zip')\n",
    "submission = pd.read_csv(dirc + 'sample_submission.csv.zip', compression='zip')\n",
    "\n",
    "print(dt.datetime.now(), 'finish reading data')\n",
    "\n",
    "test.drop('ID_code', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-08 22:38:20.766268 finish splitting data\n",
      "2019-03-08 22:38:20.766509 start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88630508 0.89551402 0.89299577 0.89613434] mean = 0.8927373027309772\n",
      "2019-03-08 22:46:15.231546 finish training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = \\\n",
    "    train_test_split(train.drop(['ID_code', 'target'], axis=1), train.target, test_size = 0.10) \n",
    "\n",
    "print(dt.datetime.now(), 'finish splitting data')\n",
    "\n",
    "print(dt.datetime.now(), 'start training...')\n",
    "\n",
    "model_cv = XGBClassifier(n_estimators=2000, n_jobs=16, learning_rate=0.05) \n",
    "cvs = cross_val_score(model_cv, train_x, train_y, \n",
    "                      cv=4, scoring='roc_auc', verbose=2, n_jobs=4, \n",
    "                      fit_params={\n",
    "                          'verbose': True, 'eval_set': [(val_x, val_y)], 'eval_metric': 'auc', \n",
    "                          'early_stopping_rounds': 20\n",
    "                      })\n",
    "\n",
    "print(cvs, 'mean =', cvs.mean())\n",
    "print(dt.datetime.now(), 'finish training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular train_test_split xgboost training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-08 23:03:54.171494 finish splitting data\n",
      "2019-03-08 23:03:54.171700 start training...\n",
      "roc_auc_score: 0.9007538640204167\n",
      "2019-03-08 23:08:50.250454 finish training\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = \\\n",
    "    train_test_split(train.drop(['ID_code', 'target'], axis=1), train.target, test_size = 0.10) \n",
    "\n",
    "print(dt.datetime.now(), 'finish splitting data')\n",
    "\n",
    "print(dt.datetime.now(), 'start training...')\n",
    "\n",
    "model = XGBClassifier(n_estimators=2000, n_jobs=32, learning_rate=0.05) \n",
    "model.fit(train_x, train_y, eval_set=[(val_x, val_y)], \n",
    "          verbose=False,\n",
    "          eval_metric='auc', early_stopping_rounds=20)\n",
    "\n",
    "pred = model.predict_proba(val_x)[:, 1]\n",
    "print('roc_auc_score:', roc_auc_score(val_y, pred))\n",
    "\n",
    "# sns.distplot(pred - val_y) \n",
    "\n",
    "print(dt.datetime.now(), 'finish training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval function versus training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_auc = model.evals_result()['validation_0']['auc']\n",
    "\n",
    "plt.figure(figsize=(10, 6.18))\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('auc')\n",
    "sns.lineplot(x = range(len(eval_auc)), y = eval_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(val_y, pred)\n",
    "score = roc_auc_score(val_y, pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.plot(fpr, fpr, linestyle='--')\n",
    "plt.plot(fpr, tpr, label='ROC: '+str(score))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = model.predict_proba(test)[:, 1]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
